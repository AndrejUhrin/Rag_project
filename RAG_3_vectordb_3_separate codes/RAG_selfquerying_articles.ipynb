{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.schema import Document, SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(temperature=0, groq_api_key=api_key, model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"../RAG_3_vectordb_3_separate codes/article_chroma_db\"\n",
    "vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"article_id\",\n",
    "        description=\"Article ID of the paper\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"authors\",\n",
    "                description=\"Authors of the paper\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"Year the paper was published\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"abstract\",\n",
    "        description=\"Abstract of the article\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"Title of the paper\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"keywords\",\n",
    "        description=\"Keywords associated with the paper\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"citation_count\",\n",
    "        description=\"Number of citations the paper has received\",\n",
    "        type=\"integer\",\n",
    "    )\n",
    "]\n",
    "\n",
    "document_content_description = \"Provides information about article\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=chat,\n",
    "    vectorstore=vectorstore,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from langchain.callbacks.base import BaseCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 23:30:08,088 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\\n\\n<< Example 1. >>\\nData Source:\\n```json\\n{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {\\n        \"artist\": {\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        },\\n        \"length\": {\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        },\\n        \"genre\": {\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }\\n    }\\n}\\n```\\n\\nUser Query:\\nWhat are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre\\n\\nStructured Request:\\n```json\\n{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}\\n```\\n\\n\\n<< Example 2. >>\\nData Source:\\n```json\\n{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {\\n        \"artist\": {\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        },\\n        \"length\": {\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        },\\n        \"genre\": {\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }\\n    }\\n}\\n```\\n\\nUser Query:\\nWhat are songs that were not published on Spotify\\n\\nStructured Request:\\n```json\\n{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}\\n```\\n\\n\\n<< Example 3. >>\\nData Source:\\n```json\\n{\\n    \"content\": \"Provides information about article\",\\n    \"attributes\": {\\n    \"article_id\": {\\n        \"description\": \"Article ID of the paper\",\\n        \"type\": \"string\"\\n    },\\n    \"authors\": {\\n        \"description\": \"Authors of the paper\",\\n        \"type\": \"string or list[string]\"\\n    },\\n    \"year\": {\\n        \"description\": \"Year the paper was published\",\\n        \"type\": \"integer\"\\n    },\\n    \"abstract\": {\\n        \"description\": \"Abstract of the article\",\\n        \"type\": \"string\"\\n    },\\n    \"title\": {\\n        \"description\": \"Title of the paper\",\\n        \"type\": \"string\"\\n    },\\n    \"keywords\": {\\n        \"description\": \"Keywords associated with the paper\",\\n        \"type\": \"string or list[string]\"\\n    },\\n    \"citation_count\": {\\n        \"description\": \"Number of citations the paper has received\",\\n        \"type\": \"integer\"\\n    }\\n}\\n}\\n```\\n\\nUser Query:\\nArticle that was published in year 2013 and citation count higher than 90.\\n\\nStructured Request:\\n'}], 'model': 'llama3-70b-8192', 'n': 1, 'stream': False, 'temperature': 1e-08}}\n",
      "2024-07-21 23:30:08,089 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions\n",
      "2024-07-21 23:30:08,091 - httpcore.connection - DEBUG - close.started\n",
      "2024-07-21 23:30:08,093 - httpcore.connection - DEBUG - close.complete\n",
      "2024-07-21 23:30:08,095 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2024-07-21 23:30:08,116 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D69860AC90>\n",
      "2024-07-21 23:30:08,116 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D6EC48C320> server_hostname='api.groq.com' timeout=None\n",
      "2024-07-21 23:30:08,142 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D6986082D0>\n",
      "2024-07-21 23:30:08,142 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-21 23:30:08,144 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2024-07-21 23:30:08,144 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-21 23:30:08,145 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2024-07-21 23:30:08,146 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-21 23:30:08,644 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jul 2024 21:30:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'4942'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'10.58s'), (b'x-request-id', b'req_01j3bk7cs1f1ybf4jpjdv5nbx2'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a6e4a5798263bba-WAW'), (b'Content-Encoding', b'gzip')])\n",
      "2024-07-21 23:30:08,646 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-21 23:30:08,647 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-21 23:30:08,650 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2024-07-21 23:30:08,652 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2024-07-21 23:30:08,652 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2024-07-21 23:30:08,653 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\" Headers({'date': 'Sun, 21 Jul 2024 21:30:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '4942', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '10.58s', 'x-request-id': 'req_01j3bk7cs1f1ybf4jpjdv5nbx2', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8a6e4a5798263bba-WAW', 'content-encoding': 'gzip'})\n",
      "2024-07-21 23:30:08,655 - langchain.retrievers.self_query.base - INFO - Generated Query: query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Title: When Does Technology Use Enable Network Change in Organizations? A Comparative Study of Feature Use and Shared Affordances Authors: Leonardi, Paul M. Publication Year: 2013 Abstract: The goal of this study is to augment explanations of how newly implemented technologies enable network change within organizations with an understanding of when such change is likely to happen. Drawing on the emerging literature on technology affordances, the paper suggests that informal network change within interdependent organizational groups is unlikely to occur until users converge on a shared appropriation of the new technology's features such that the affordances the technology enables are jointly realized. In making the argument for the importance of shared affordances, this paper suggests that group-level network change has its most profound implications at the organization level when individuals use the same subset of a new information technology's features. To explore this tentative theory, we turn to a comparative, multimethod, longitudinal study of computer-based simulation technology use in automotive engineering. The findings of this explanatory case study show that engineers used the new technology for more than three months, during which time neither group experienced changes to their advice networks. Initially, divergent uses of the technology's features by engineers in both groups precluded them from being able to coordinate their work in ways that allowed them to structure their advice networks differently. Eventually, engineers in only one of the two groups converged on the use of a common set of the technology's features to enact a shared affordance. This convergence was necessary to turn the technology into a resource that could collectively afford group members the ability to compare their simulation outputs with one another and, in so doing, alter the content and structure of the group's advice network. The implications of these findings for the literatures on technology feature use, affordances, social networks, and post-adoption behaviors in organizations are discussed. Keywords: Technology implementation, organizational change, advice networks, feature use, affordances, frames Citation Count: 97\", metadata={'abstract': \"The goal of this study is to augment explanations of how newly implemented technologies enable network change within organizations with an understanding of when such change is likely to happen. Drawing on the emerging literature on technology affordances, the paper suggests that informal network change within interdependent organizational groups is unlikely to occur until users converge on a shared appropriation of the new technology's features such that the affordances the technology enables are jointly realized. In making the argument for the importance of shared affordances, this paper suggests that group-level network change has its most profound implications at the organization level when individuals use the same subset of a new information technology's features. To explore this tentative theory, we turn to a comparative, multimethod, longitudinal study of computer-based simulation technology use in automotive engineering. The findings of this explanatory case study show that engineers used the new technology for more than three months, during which time neither group experienced changes to their advice networks. Initially, divergent uses of the technology's features by engineers in both groups precluded them from being able to coordinate their work in ways that allowed them to structure their advice networks differently. Eventually, engineers in only one of the two groups converged on the use of a common set of the technology's features to enact a shared affordance. This convergence was necessary to turn the technology into a resource that could collectively afford group members the ability to compare their simulation outputs with one another and, in so doing, alter the content and structure of the group's advice network. The implications of these findings for the literatures on technology feature use, affordances, social networks, and post-adoption behaviors in organizations are discussed.\", 'authors': 'Leonardi, Paul M.', 'citation_count': 97, 'keywords': 'Technology implementation, organizational change, advice networks, feature use, affordances, frames', 'title': 'When Does Technology Use Enable Network Change in Organizations? A Comparative Study of Feature Use and Shared Affordances', 'year': 2013})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Article that was published in year 2013 and citation count higher than 90.\"\n",
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilteredLogHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        log_entry = self.format(record)\n",
    "        if 'Generated Query' in log_entry:\n",
    "            # Print only the relevant part of the log entry\n",
    "            print(log_entry.split('Generated Query: ')[1])\n",
    "\n",
    "# Configure the logging to use the custom handler\n",
    "logger = logging.getLogger('langchain.retrievers.self_query.base')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create and add the custom handler\n",
    "handler = FilteredLogHandler()\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 23:23:31,421 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\\n\\n<< Example 1. >>\\nData Source:\\n```json\\n{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {\\n        \"artist\": {\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        },\\n        \"length\": {\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        },\\n        \"genre\": {\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }\\n    }\\n}\\n```\\n\\nUser Query:\\nWhat are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre\\n\\nStructured Request:\\n```json\\n{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}\\n```\\n\\n\\n<< Example 2. >>\\nData Source:\\n```json\\n{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {\\n        \"artist\": {\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        },\\n        \"length\": {\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        },\\n        \"genre\": {\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }\\n    }\\n}\\n```\\n\\nUser Query:\\nWhat are songs that were not published on Spotify\\n\\nStructured Request:\\n```json\\n{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}\\n```\\n\\n\\n<< Example 3. >>\\nData Source:\\n```json\\n{\\n    \"content\": \"Provides information about article\",\\n    \"attributes\": {\\n    \"article_id\": {\\n        \"description\": \"Article ID of the paper\",\\n        \"type\": \"string\"\\n    },\\n    \"authors\": {\\n        \"description\": \"Authors of the paper\",\\n        \"type\": \"string or list[string]\"\\n    },\\n    \"year\": {\\n        \"description\": \"Year the paper was published\",\\n        \"type\": \"integer\"\\n    },\\n    \"abstract\": {\\n        \"description\": \"Abstract of the article\",\\n        \"type\": \"string\"\\n    },\\n    \"title\": {\\n        \"description\": \"Title of the paper\",\\n        \"type\": \"string\"\\n    },\\n    \"keywords\": {\\n        \"description\": \"Keywords associated with the paper\",\\n        \"type\": \"string or list[string]\"\\n    },\\n    \"citation_count\": {\\n        \"description\": \"Number of citations the paper has received\",\\n        \"type\": \"integer\"\\n    }\\n}\\n}\\n```\\n\\nUser Query:\\nArticle that was published in year 2013 and citation count higher than 90.\\n\\nStructured Request:\\n'}], 'model': 'llama3-70b-8192', 'n': 1, 'stream': False, 'temperature': 1e-08}}\n",
      "2024-07-21 23:23:31,423 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions\n",
      "2024-07-21 23:23:31,424 - httpcore.connection - DEBUG - close.started\n",
      "2024-07-21 23:23:31,426 - httpcore.connection - DEBUG - close.complete\n",
      "2024-07-21 23:23:31,428 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2024-07-21 23:23:31,528 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D6985FDF90>\n",
      "2024-07-21 23:23:31,528 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D6EC48C320> server_hostname='api.groq.com' timeout=None\n",
      "2024-07-21 23:23:31,554 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D69612BF10>\n",
      "2024-07-21 23:23:31,555 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-21 23:23:31,556 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2024-07-21 23:23:31,556 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-21 23:23:31,557 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2024-07-21 23:23:31,557 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-21 23:23:32,027 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jul 2024 21:23:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'4942'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'10.58s'), (b'x-request-id', b'req_01j3bjv9fse778qbd3hpg78qg4'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dxyA4tiIiA1_ag34btixkupMoUMW.kLZIJUfZA5gYT4-1721597011-1.0.1.1-W4.CjsQdjMhOc.JteYyWONGqysh2M8bBwUglC8_0ESsZtI1nM.INZo2XUQlswoNH_85krDA3NdEeAXVhT9xE9A; path=/; expires=Sun, 21-Jul-24 21:53:31 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a6e40a8ff3cbbc0-WAW'), (b'Content-Encoding', b'gzip')])\n",
      "2024-07-21 23:23:32,028 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-21 23:23:32,029 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-21 23:23:32,031 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2024-07-21 23:23:32,031 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2024-07-21 23:23:32,032 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2024-07-21 23:23:32,032 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\" Headers({'date': 'Sun, 21 Jul 2024 21:23:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '4942', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '10.58s', 'x-request-id': 'req_01j3bjv9fse778qbd3hpg78qg4', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=dxyA4tiIiA1_ag34btixkupMoUMW.kLZIJUfZA5gYT4-1721597011-1.0.1.1-W4.CjsQdjMhOc.JteYyWONGqysh2M8bBwUglC8_0ESsZtI1nM.INZo2XUQlswoNH_85krDA3NdEeAXVhT9xE9A; path=/; expires=Sun, 21-Jul-24 21:53:31 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8a6e40a8ff3cbbc0-WAW', 'content-encoding': 'gzip'})\n",
      "2024-07-21 23:23:32,035 - langchain.retrievers.self_query.base - INFO - Generated Query: query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n"
     ]
    }
   ],
   "source": [
    "query = \"Article that was published in year 2013 and citation count higher than 90.\"\n",
    "\n",
    "# Execute the query\n",
    "documents = retriever.get_relevant_documents(query, config={'callbacks': [ConsoleCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question. Always answear the question as if you were a human and answear in full sentance. During your answear be really specific. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_prompt():\n",
    "    \"\"\"\n",
    "    Prompt template for QA retrieval for each vectorstore\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=custom_prompt_template,\n",
    "                            input_variables=['context', 'question'])\n",
    "    return prompt\n",
    "\n",
    "prompt = set_custom_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    chain_type='stuff',\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={'prompt': prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "2024-07-22 00:13:50,977 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\\n\\n<< Example 1. >>\\nData Source:\\n```json\\n{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {\\n        \"artist\": {\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        },\\n        \"length\": {\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        },\\n        \"genre\": {\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }\\n    }\\n}\\n```\\n\\nUser Query:\\nWhat are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre\\n\\nStructured Request:\\n```json\\n{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}\\n```\\n\\n\\n<< Example 2. >>\\nData Source:\\n```json\\n{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {\\n        \"artist\": {\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        },\\n        \"length\": {\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        },\\n        \"genre\": {\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }\\n    }\\n}\\n```\\n\\nUser Query:\\nWhat are songs that were not published on Spotify\\n\\nStructured Request:\\n```json\\n{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}\\n```\\n\\n\\n<< Example 3. >>\\nData Source:\\n```json\\n{\\n    \"content\": \"Provides information about article\",\\n    \"attributes\": {\\n    \"article_id\": {\\n        \"description\": \"Article ID of the paper\",\\n        \"type\": \"string\"\\n    },\\n    \"authors\": {\\n        \"description\": \"Authors of the paper\",\\n        \"type\": \"string or list[string]\"\\n    },\\n    \"year\": {\\n        \"description\": \"Year the paper was published\",\\n        \"type\": \"integer\"\\n    },\\n    \"abstract\": {\\n        \"description\": \"Abstract of the article\",\\n        \"type\": \"string\"\\n    },\\n    \"title\": {\\n        \"description\": \"Title of the paper\",\\n        \"type\": \"string\"\\n    },\\n    \"keywords\": {\\n        \"description\": \"Keywords associated with the paper\",\\n        \"type\": \"string or list[string]\"\\n    },\\n    \"citation_count\": {\\n        \"description\": \"Number of citations the paper has received\",\\n        \"type\": \"integer\"\\n    }\\n}\\n}\\n```\\n\\nUser Query:\\nArticle that was published in year 2013 and citation count higher than 90\\n\\nStructured Request:\\n'}], 'model': 'llama3-70b-8192', 'n': 1, 'stream': False, 'temperature': 1e-08}}\n",
      "2024-07-22 00:13:50,979 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions\n",
      "2024-07-22 00:13:50,979 - httpcore.connection - DEBUG - close.started\n",
      "2024-07-22 00:13:50,981 - httpcore.connection - DEBUG - close.complete\n",
      "2024-07-22 00:13:50,981 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2024-07-22 00:13:51,104 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D69869EBD0>\n",
      "2024-07-22 00:13:51,104 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D6EC48C320> server_hostname='api.groq.com' timeout=None\n",
      "2024-07-22 00:13:51,133 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D6985C7750>\n",
      "2024-07-22 00:13:51,135 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-22 00:13:51,135 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2024-07-22 00:13:51,135 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-22 00:13:51,136 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2024-07-22 00:13:51,136 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-22 00:13:52,066 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jul 2024 22:13:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'4943'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'10.57s'), (b'x-request-id', b'req_01j3bnqe8he6svhcvjg8kwq3a6'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=8toCI2wKLnR1HzbFtWn_wywzLJwglDgGLZDn53YjCmw-1721600031-1.0.1.1-4wW_fGWK2YZFLuoLaHSOY2Do5K3WJazFf49zEcvqr_E6G4ahH2IXPPLIRVpXjEi2kQh9pEBj2G5UjLXB7DHv5A; path=/; expires=Sun, 21-Jul-24 22:43:51 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a6e8a611b86bfdc-WAW'), (b'Content-Encoding', b'gzip')])\n",
      "2024-07-22 00:13:52,067 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-22 00:13:52,068 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-22 00:13:52,068 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2024-07-22 00:13:52,069 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2024-07-22 00:13:52,069 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2024-07-22 00:13:52,070 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\" Headers({'date': 'Sun, 21 Jul 2024 22:13:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '4943', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '10.57s', 'x-request-id': 'req_01j3bnqe8he6svhcvjg8kwq3a6', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=8toCI2wKLnR1HzbFtWn_wywzLJwglDgGLZDn53YjCmw-1721600031-1.0.1.1-4wW_fGWK2YZFLuoLaHSOY2Do5K3WJazFf49zEcvqr_E6G4ahH2IXPPLIRVpXjEi2kQh9pEBj2G5UjLXB7DHv5A; path=/; expires=Sun, 21-Jul-24 22:43:51 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '8a6e8a611b86bfdc-WAW', 'content-encoding': 'gzip'})\n",
      "2024-07-22 00:13:52,073 - langchain.retrievers.self_query.base - INFO - Generated Query: query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "2024-07-22 00:13:52,101 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Use the following pieces of information to answer the user's question. Always answear the question as if you were a human and answear in full sentance. During your answear be really specific. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n\\n\\nContext: Title: When Does Technology Use Enable Network Change in Organizations? A Comparative Study of Feature Use and Shared Affordances Authors: Leonardi, Paul M. Publication Year: 2013 Abstract: The goal of this study is to augment explanations of how newly implemented technologies enable network change within organizations with an understanding of when such change is likely to happen. Drawing on the emerging literature on technology affordances, the paper suggests that informal network change within interdependent organizational groups is unlikely to occur until users converge on a shared appropriation of the new technology's features such that the affordances the technology enables are jointly realized. In making the argument for the importance of shared affordances, this paper suggests that group-level network change has its most profound implications at the organization level when individuals use the same subset of a new information technology's features. To explore this tentative theory, we turn to a comparative, multimethod, longitudinal study of computer-based simulation technology use in automotive engineering. The findings of this explanatory case study show that engineers used the new technology for more than three months, during which time neither group experienced changes to their advice networks. Initially, divergent uses of the technology's features by engineers in both groups precluded them from being able to coordinate their work in ways that allowed them to structure their advice networks differently. Eventually, engineers in only one of the two groups converged on the use of a common set of the technology's features to enact a shared affordance. This convergence was necessary to turn the technology into a resource that could collectively afford group members the ability to compare their simulation outputs with one another and, in so doing, alter the content and structure of the group's advice network. The implications of these findings for the literatures on technology feature use, affordances, social networks, and post-adoption behaviors in organizations are discussed. Keywords: Technology implementation, organizational change, advice networks, feature use, affordances, frames Citation Count: 97\\nQuestion: Article that was published in year 2013 and citation count higher than 90\\n\\nOnly return the helpful answer below and nothing else.\\nHelpful answer:\\n\"}], 'model': 'llama3-70b-8192', 'n': 1, 'stream': False, 'temperature': 1e-08}}\n",
      "2024-07-22 00:13:52,102 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions\n",
      "2024-07-22 00:13:52,103 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-22 00:13:52,103 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2024-07-22 00:13:52,105 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-22 00:13:52,106 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2024-07-22 00:13:52,107 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2013), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='citation_count', value=90)]) limit=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:13:52,626 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Jul 2024 22:13:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'4329'), (b'x-ratelimit-reset-requests', b'11.064999999s'), (b'x-ratelimit-reset-tokens', b'16.701999999s'), (b'x-request-id', b'req_01j3bnqf6pefw8gtrn8yyx46ab'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a6e8a672f14bfdc-WAW'), (b'Content-Encoding', b'gzip')])\n",
      "2024-07-22 00:13:52,630 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-22 00:13:52,631 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-22 00:13:52,636 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2024-07-22 00:13:52,637 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2024-07-22 00:13:52,639 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2024-07-22 00:13:52,643 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\" Headers({'date': 'Sun, 21 Jul 2024 22:13:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '4329', 'x-ratelimit-reset-requests': '11.064999999s', 'x-ratelimit-reset-tokens': '16.701999999s', 'x-request-id': 'req_01j3bnqf6pefw8gtrn8yyx46ab', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8a6e8a672f14bfdc-WAW', 'content-encoding': 'gzip'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The article \"When Does Technology Use Enable Network Change in Organizations? A Comparative Study of Feature Use and Shared Affordances\" by Paul M. Leonardi, published in 2013, has a citation count of 97, which meets the specified criteria.\n"
     ]
    }
   ],
   "source": [
    "query = \"Article that was published in year 2013 and citation count higher than 90\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Both articles, \"A Multilevel Model of Resistance to Information Technology Implementation\" and \"Understanding User Responses to Information Technology: A Coping Model of User Adaptation\", have a citation count higher than 250, with 296 and 299 citations, respectively.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which article had citation count higher than 250\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Article \"A Multilevel Model of Resistance to Information Technology Implementation\" has the following sections: Abstract, and possibly Introduction, Methodology, Results, Discussion, and Conclusion, although these latter sections are not explicitly mentioned in the provided context.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which sections does article A Multilevel Model of Resistance to Information Technology Implementation have\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: There were 4 articles published in 2013. The names of these articles are:\n",
      "\n",
      "1. \"An Investigation of Information Systems Use Patterns: Technological Events as Triggers, the Effect of Time, and Consequences for Performance\"\n",
      "2. \"A Dramaturgical Model of the Production of Performance Data\"\n",
      "3. \"When Does Technology Use Enable Network Change in Organizations? A Comparative Study of Feature Use and Shared Affordances\"\n",
      "4. \"The Embeddedness of Information Systems Habits in Organizational and Individual Level Routines: Development and Disruption\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me how many articles were published in 2013 and also the names of these articles\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Two article titles have \"technology adoption\" mentioned in their keywords: \"Revisiting Group-Based Technology Adoption as a Dynamic Process: The Role of Changing Attitude-Rationale Configurations\" and \"When Does Technology Use Enable Network Change in Organizations? A Comparative Study of Feature Use and Shared Affordances\".\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me number of all articles titles that have technology adoption mentioned in their keywords\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I don't know how many articles were written by Ortiz de Guinea.\n"
     ]
    }
   ],
   "source": [
    "query = \"How many articles were written by Ortiz de Guinea\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: According to my research, I found two article titles written by Ortiz de Guinea: \"The Impact of User Experience on the Adoption of E-Learning Systems\" and \"Analysis of the Role of Trust in the Adoption of E-Banking: A Case Study in Spain\".\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me titles of articles where the author was Ortiz de Guinea\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: According to the provided context, there are 2 articles where the author was Ortiz de Guinea.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me the number of articles where the author was Ortiz de Guinea\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: According to the provided information, the article \"Why Break the Habit of a Lifetime? Rethinking the Roles of Intention, Habit, and Emotion in Continuing Information Technology Use\" by Ortiz de Guinea and Markus, published in 2009, has a citation count of 75, which meets the criteria of having a citation count higher than 70.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me all articles that were published in 2009 and have citation count higher than 70.\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided information, the articles that were published in 2009 and have a citation count higher than 70 are:\n",
      "\n",
      "* \"The Integrative Framework of Technology Use: An Extension and Test\" by Kim, Sung S. with a citation count of 67 (although it doesn't meet the exact criteria, I'm including it since you asked for articles that don't meet the criteria as well)\n",
      "* \"Why Break the Habit of a Lifetime? Rethinking the Roles of Intention, Habit, and Emotion in Continuing Information Technology Use\" by Ortiz de Guinea, Ana; Markus, M. Lynne with a citation count of 75.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me all articles that were published in 2009 and have citation count higher than 70. If here are any more articles in 2009 and do not have citation count higher than 70, include them in the answer.\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The article \"When Does Technology Use Enable Network Change in Organizations? A Comparative Study of Feature Use and Shared Affordances\" was written in 2013.\n"
     ]
    }
   ],
   "source": [
    "query = \"In which year was the article When Does Technology Use Enable Network Change in Organizations? A Comparative Study of Feature Use and Shared Affordances written\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The article \"How Do Suppliers Benefit from Information Technology Use in Supply Chain Relationships?\" has the following keywords: Buyer-supplier relationships, inter-organizational systems (IOS), EDI, supply chain management systems (SCMS), transaction cost economics, intangible asset specificity, IT use, exploration, and exploitation.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which key words does article: How Do Suppliers Benefit from Information Technology Use in Supply Chain Relationships? have\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Here are the articles published in 2007, along with their title, authors, and citation count:\n",
      "\n",
      "\"How Habit Limits the Predictive Power of Intention: The Case of Information Systems Continuance\" by Limayem, Moez; Hirt, Sabine Gabriele; Cheung, Christy M. K. with a citation count of 240.\n",
      "\n",
      "\"Toward a Deeper Understanding of System Usage in Organizations: A Multilevel Perspective\" by Burton-Jones, Andrew; Gallivan, Michael J. with a citation count of 0.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me all the articles were published in 2007, but also include their title, authors and citation count\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Give me all the articles were published in 2007, but also include their title, authors and citation count\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
