{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.schema import Document, SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(temperature=0, groq_api_key=api_key, model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"../RAG_3_vectordb_3_separate_codes/paragraphs_chroma_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persist directory exists.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(persist_directory):\n",
    "    print(\"Persist directory does not exist.\")\n",
    "else:\n",
    "    print(\"Persist directory exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading already created vector database. By specifying the embedding function, we are ensuring that the same model used to create the database is being used to query it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Providing additional information about the metadata for more precise filtering and details about the document description helps the chain understand the document's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"Year the paper was published\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"Title of the paper\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"last_section_title\",\n",
    "        description=\"Title section is associated with paragraph\",\n",
    "        type=\"string\",\n",
    "    )\n",
    "]\n",
    "\n",
    "document_content_description = \"Provides context of each paragraph within the article\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the SelfQueryRetriever that is used for retriving documents from the vector database. In this chain we specify that we are using Llama 3 as our LLM model, which sees analyzes the prompt and structures it into a query, paragraphs_chroma_db as our vector database and provide also the additional attribute info about metadata and document description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=chat,\n",
    "    vectorstore=vectorstore,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a custom prompt instructs the model to always respond in full sentences and to say \"I don't know\" if it doesn't know the answer. This approach prevents Llama 3 from generating random responses simply to fulfill the expectation of an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question. Always answear the question as if you were a human and answear in full sentance. During your answear be really specific. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_prompt():\n",
    "    \"\"\"\n",
    "    Prompt template for QA retrieval for each vectorstore\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=custom_prompt_template,\n",
    "                            input_variables=['context', 'question'])\n",
    "    return prompt\n",
    "\n",
    "prompt = set_custom_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define the complete question-answering chain in RAG. We specify that Llama 3 is the LLM model in use, the retriever is the SelfQueryRetriever we created earlier, chain_type=\"stuff\" indicates a basic chain where the LLM answers based solely on the user's question and retrieved documents, and finally, we ensure that the custom prompt we created is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    chain_type='stuff',\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={'prompt': prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The study was conducted in two stages: within-case analysis and cross-case analysis. In the within-case analysis, data was analyzed to allow the unique patterns of each case to emerge and to provide researchers with a rich understanding of each case. This was done to accelerate cross-case comparisons. In the cross-case analysis, analytic induction was used to search for common patterns and unique features. The researchers developed hypotheses prior to data analysis, which were revised to fit emerging interpretations of the data over the course of data collection and analysis. To reach an appropriate degree of internal validity, three sources of evidence were used: direct observation, documentation, and interviews. The researchers spent several days at each site observing how each EMR was used, analyzed system and project documentation, and conducted interviews. Data gathered from these sources was used to corroborate, validate, and complement the interview data. Cross-case analysis was conducted using two tactics: categories were selected to identify patterns in each dimension of the framework, and cases were compared in pairs to identify subtle similarities and differences between them. The chains of evidence developed in the within-case analyses helped build a general explanation that could be applied to each individual case, while simultaneously taking into account differences between cases. Research sites were selected to maximize variation and allow comparison, with similarities and variations in three characteristics of the cases: hospital type, software package, and outcome.\n"
     ]
    }
   ],
   "source": [
    "query = \"How was study conduted in article: A Multilevel Model of Resistance to Information Technology Implementation, be very specififc\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Yes, the case study mentioned in the article is about Autoworks, a company in the automotive industry, specifically focusing on the Safety division, where the researcher spent nine months conducting ethnographic data collection and administered sociometric surveys to engineers in the Piston and Strut groups to study the impact of CrashLab technology on their network and advice-seeking behaviors.\n"
     ]
    }
   ],
   "source": [
    "query = \"Is case study mentioned in article When Does Technology Use Enable Network Change in Organizations? A Comparative Study of Feature Use and Shared Affordances\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: No, a case study is not mentioned in the article \"Understanding User Revisions When Using Information System Features: Adaptive System Use and Triggers\". Instead, the study used a survey and Q-sorting method, as described in the Research Design and Step 2: Interviews sections, respectively.\n"
     ]
    }
   ],
   "source": [
    "query = \"Is case study mentioned in article: Understanding User Revisions When Using Information System Features: Adaptive System Use and Triggers. if it is not mentioned, which kind of study was used\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The group of people involved in the survey in the article \"How Habit Limits the Predictive Power of Intention: The Case of Information Systems Continuance\" were business students at a university in Hong Kong.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which groups of people were involved in the survey in article: How Habit Limits the Predictive Power of Intention: The Case of Information Systems Continuance.\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
