{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.schema import Document, SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(temperature=0, groq_api_key=api_key, model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"../Rag_project/RAG_multiple_vector_stores/paragraphs_chroma_db_MISQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persist directory exists.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(persist_directory):\n",
    "    print(\"Persist directory does not exist.\")\n",
    "else:\n",
    "    print(\"Persist directory exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: ['bf72155b-3b8e-4318-817a-84489ad406e1', 'chroma.sqlite3']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(persist_directory)\n",
    "print(f\"Files in directory: {files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read permission granted for directory: C:\\Users\\andyu\\OneDrive\\Počítač\\Text, Web and Social Media Analytics Lab\\Rag_project\\RAG_multiple_vector_stores\\paragraphs_chroma_db_MISQ\n",
      "Read permission granted for file: bf72155b-3b8e-4318-817a-84489ad406e1\n",
      "Read permission granted for file: chroma.sqlite3\n"
     ]
    }
   ],
   "source": [
    "if os.access(persist_directory, os.R_OK):\n",
    "    print(f\"Read permission granted for directory: {persist_directory}\")\n",
    "else:\n",
    "    print(f\"Read permission denied for directory: {persist_directory}\")\n",
    "\n",
    "# Check permissions for individual files\n",
    "for file in files:\n",
    "    file_path = os.path.join(persist_directory, file)\n",
    "    if os.access(file_path, os.R_OK):\n",
    "        print(f\"Read permission granted for file: {file}\")\n",
    "    else:\n",
    "        print(f\"Read permission denied for file: {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header file does not exist: C:\\Users\\andyu\\OneDrive\\Počítač\\Text, Web and Social Media Analytics Lab\\Rag_project\\RAG_multiple_vector_stores\\paragraphs_chroma_db_MISQ\\../RAG_multiple_vector_stores/paragraphs_chroma_db_MISQ/bf72155b-3b8e-4318-817a-84489ad406e1/header.bin\n"
     ]
    }
   ],
   "source": [
    "header_file = '../RAG_multiple_vector_stores/paragraphs_chroma_db_MISQ/bf72155b-3b8e-4318-817a-84489ad406e1/header.bin'  # Replace with the actual header file name\n",
    "header_file_path = os.path.join(persist_directory, header_file)\n",
    "\n",
    "if os.path.exists(header_file_path):\n",
    "    print(f\"Header file exists: {header_file_path}\")\n",
    "else:\n",
    "    print(f\"Header file does not exist: {header_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore2 = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the vector store: 1829\n"
     ]
    }
   ],
   "source": [
    "num_documents = len(vectorstore2)\n",
    "print(f\"Number of documents in the vector store: {num_documents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated metadata field info to match the new column names\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"para_id\",\n",
    "        description=\"Paragraph ID of the section\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"Title of the article\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"last_section_title\",\n",
    "        description=\"Title of the section so it is connected to paragraph\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"paragraph\",\n",
    "        description=\"Content of the paragraph\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"ent_id\",\n",
    "        description=\"Entities mentioned in the paragraph\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"level3\",\n",
    "        description=\"More general entities mentioned in the paragraph\",\n",
    "        type=\"string or list[string]\",\n",
    "    )\n",
    "]\n",
    "\n",
    "# Description of the document content\n",
    "document_content_description = \"Brief summary of the article, including paragraph content and entities from the text\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SelfQueryRetriever\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=chat,\n",
    "    vectorstore=vectorstore2,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "query = \"Which sections titles does article Nature and Nurture: The Impact of Automaticity on Virtual Team Behavior and Performance has\"\n",
    "results = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results found.\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "if not results:\n",
    "    print(\"No results found.\")\n",
    "else:\n",
    "    for result in results:\n",
    "        print(result.page_content)\n",
    "        print(result.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the setup and initialization are already done and the necessary imports are available\n",
    "\n",
    "# Define the custom prompt template\n",
    "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question. Always answer the question as if you were a human and in full sentance. If you don't know the answer, just say that you don't know, don't try to make up an answer. Only use information from the datasource.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "# Function to generate the fluent output using the LLM\n",
    "def generate_fluent_output(query, retriever, chat, custom_prompt_template):\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    # Combine the contents and metadata of the results\n",
    "    combined_content = \"\\n\\n\".join([f\"{doc.page_content}\\nMetadata: {doc.metadata}\" for doc in results])\n",
    "    \n",
    "    # Create a prompt for the LLM to transform the output\n",
    "    formatted_prompt = custom_prompt_template.format(context=combined_content, question=query)\n",
    "    messages = [\n",
    "        HumanMessage(content=formatted_prompt)\n",
    "    ]\n",
    "    \n",
    "    # Get the LLM response\n",
    "    response = chat(messages)\n",
    "    fluent_output = response.content\n",
    "    \n",
    "    # Print the fluent output\n",
    "    print(fluent_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entities mentioned in the article \"Nature and Nurture: The A Temporally Situated Self-Agency Theory of Information Technology Reinvention\" are not explicitly stated.\n"
     ]
    }
   ],
   "source": [
    "# Your query\n",
    "query = \"Which entities are in article Nature and Nurture: The A Temporally Situated Self-Agency Theory of Information Technology Reinvention.\"\n",
    "\n",
    "# Generate and print the fluent output\n",
    "generate_fluent_output(query, retriever, chat, custom_prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the article does not have \"technology adoption\" in its keywords, but it does have \"technology use\" and \"continued use\".\n"
     ]
    }
   ],
   "source": [
    "query = \"Does this article has technology adoptation in keywords: The Integrative Framework of Technology Use: An Extension and Test?\"\n",
    "\n",
    "# Generate and print the fluent output\n",
    "generate_fluent_output(query, retriever, chat, custom_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
