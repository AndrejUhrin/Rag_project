{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/kiri/Documents/HWR/master/SS/Text & Web/Rag_project-1/first attempt rag\n",
      "GROQ_API_KEY: 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\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatGroq' object has no attribute 'completions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m chat \u001b[38;5;241m=\u001b[39m ChatGroq(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, groq_api_key\u001b[38;5;241m=\u001b[39mapi_key, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3-70b-8192\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Example usage of the ChatGroq client - Replace with the correct method if available\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     29\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain the importance of fast language models\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatGroq' object has no attribute 'completions'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import ChatGroq\n",
    "\n",
    "# Print the current working directory\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Specify the path to the .env file\n",
    "env_path = '.env'\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Retrieve the API key from the environment variables\n",
    "api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "# Debug: Print the API key to ensure it's being loaded correctly\n",
    "print(f\"GROQ_API_KEY: {api_key}\")\n",
    "\n",
    "# Check if the API key is None and raise an error if it is\n",
    "if api_key is None:\n",
    "    raise ValueError(\"GROQ_API_KEY environment variable is not set. Please check your .env file and ensure it contains the correct key-value pair.\")\n",
    "\n",
    "# Initialize the ChatGroq client with the API key and other parameters\n",
    "chat = ChatGroq(temperature=0, groq_api_key=api_key, model_name=\"llama3-70b-8192\")\n",
    "\n",
    "# Example usage of the ChatGroq client\n",
    "response = chat.chat_completion(messages=[{\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}])\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatGroq\n__root__\n  Did not find groq_api_key, please add an environment variable `GROQ_API_KEY` which contains it, or pass `groq_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[43mChatGroq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroq_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama3-70b-8192\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatGroq\n__root__\n  Did not find groq_api_key, please add an environment variable `GROQ_API_KEY` which contains it, or pass `groq_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "#chat = ChatGroq(temperature=0, groq_api_key=api_key, model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "persist_directory = 'chroma_db'\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'persist_directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m Chroma(persist_directory\u001b[38;5;241m=\u001b[39m\u001b[43mpersist_directory\u001b[49m,\n\u001b[1;32m      2\u001b[0m                   embedding_function\u001b[38;5;241m=\u001b[39membedding_model,\n\u001b[1;32m      3\u001b[0m                   collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle_abstract_chroma_db\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'persist_directory' is not defined"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embedding_model,\n",
    "                  collection_name=\"title_abstract_chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_prompt():\n",
    "    \"\"\"\n",
    "    Prompt template for QA retrieval for each vectorstore\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=custom_prompt_template,\n",
    "                            input_variables=['context', 'question'])\n",
    "    return prompt\n",
    "\n",
    "prompt = set_custom_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m qa \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[0;32m----> 2\u001b[0m     llm\u001b[38;5;241m=\u001b[39m\u001b[43mchat\u001b[49m,\n\u001b[1;32m      3\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mretriever,\n\u001b[1;32m      5\u001b[0m     return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     chain_type_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt}\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chat' is not defined"
     ]
    }
   ],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    chain_type='stuff',\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={'prompt': prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me 2 articles that talk about ad blockers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mqa\u001b[49m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qa' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"Give me 2 articles that talk about ad blockers.\"\n",
    "result = qa({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Here are 2 articles that talk about ad blockers:\n",
      "\n",
      "1. Ad-Blockers: A Blessing or a Curse?\n",
      "2. (No other article talks about ad blockers)\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The article \"Essence: facilitating software innovation\" talks about software innovation.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me articles that talk about software innovation.\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The article \"Data Science for Social Good\" is about the diminishing emphasis on social good challenges in data science research, and presents a framework for \"data science for social good\" research that considers the interplay between relevant data science research genres, social good challenges, and different levels of sociotechnical abstraction.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is article with the name Data Science for Scoial Good about.\"\n",
    "result = qa({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " The article \"Data Science for Social Good\" is about presenting a framework for\n",
      "\"data science for social good\" (DSSG) research that considers the interplay\n",
      "between relevant data science research genres, social good challenges, and\n",
      "different levels of sociotechnical abstraction, and highlighting the lack of\n",
      "research focus on social good challenges in the field of data science.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the article with the name Data Science for Social Good about.\"\n",
    "result = qa({\"query\": query})\n",
    "wrapped_answer = textwrap.fill(result[\"result\"], width=80)\n",
    "print(\"Answer:\\n\", wrapped_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " Here is the abstract of the article \"Data Science for Social Good\":  Data\n",
      "science has been described as the fourth paradigm of scientific discovery. The\n",
      "latest wave of data science research, pertaining to machine learning and\n",
      "artificial intelligence (AI), is growing exponentially and garnering millions of\n",
      "annual citations. However, this growth has been accompanied by a diminishing\n",
      "emphasis on social good challenges-our analysis reveals that the proportion of\n",
      "data science research focusing on social good is less than it has ever been. At\n",
      "the same time, the proliferation of machine learning and generative AI has\n",
      "sparked debates about the sociotechnical prospects and challenges associated\n",
      "with data science for human flourishing, organizations, and society. Against\n",
      "this backdrop, we present a framework for \"data science for social good\" (DSSG)\n",
      "research that considers the interplay between relevant data science research\n",
      "genres, social good challenges, and different levels of sociotechnical\n",
      "abstraction. We perform an analysis of the literature to empirically demonstrate\n",
      "the paucity of work on DSSG in information systems (and other related\n",
      "disciplines) and highlight current impediments. We then use our proposed\n",
      "framework to introduce the articles appearing in the JAIS special issue on data\n",
      "science for social good.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me full abstract of article Data Science for Social Good.\"\n",
    "result = qa({\"query\": query})\n",
    "wrapped_answer = textwrap.fill(result[\"result\"], width=80)\n",
    "print(\"Answer:\\n\", wrapped_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
