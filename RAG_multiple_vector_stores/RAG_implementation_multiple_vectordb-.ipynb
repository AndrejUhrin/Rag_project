{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains.router.multi_retrieval_qa import MultiRetrievalQAChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our LLM model. We are using Llama 3 which we are able to access through Groq whith their API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting model to Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(temperature=0, groq_api_key=api_key, model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the directories where we have stored our vector databases, and making sure that the directory exists. (In the previous attempts we have experienced problem with setting the directories so this is just a safety measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory1 = '../RAG_multiple_vector_stores/article_chroma_db_MISQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persist directory exists.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(persist_directory1):\n",
    "    print(\"Persist directory does not exist.\")\n",
    "else:\n",
    "    print(\"Persist directory exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory2 = '../RAG_multiple_vector_stores/sentence_chroma_db_MISQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persist directory exists.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(persist_directory2):\n",
    "    print(\"Persist directory does not exist.\")\n",
    "else:\n",
    "    print(\"Persist directory exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the created vector databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_articles = Chroma(embedding_function=embedding_model,\n",
    "                           persist_directory=persist_directory1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_sentences = Chroma(embedding_function=embedding_model,\n",
    "                           persist_directory=persist_directory2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting them up as retrievers so we can use them in the QAchain as a source of our information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_articles = vectordb_articles.as_retriever()\n",
    "retriever_sentences = vectordb_sentences.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question accurately, only answear the information what I am asking about.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Provide a concise and relevant answer below:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_articles = PromptTemplate(template=custom_prompt_template, input_variables=['context', 'question'])\n",
    "prompt_sentences = PromptTemplate(template=custom_prompt_template, input_variables=['context', 'question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating information about the retrievers to distinguish them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_infos = [\n",
    "    {\"name\": \"Articles\", \"description\": \"Information about articles such as name, authors, abstract, journal the article was published in,keywords from the article, year published, and citation count.\", \"retriever\": retriever_articles, \"prompt\": prompt_articles},\n",
    "    {\"name\": \"Sentences\", \"description\": \"Provides information about title, sentences in the article, and names of sections and sentence type under the sentence falls.\", \"retriever\": retriever_sentences, \"prompt\": prompt_sentences},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_infos = [\n",
    "    {\"name\": \"Articles\", \"description\": \"Contains metadata about articles such as title, authors, abstract, journal, keywords, year of publication, and citation count.\", \"retriever\": retriever_articles, \"prompt\": prompt_articles},\n",
    "    {\"name\": \"Sentences\", \"description\": \"Contains detailed sentences and paragraphs from articles, including titles, section names, and sentence types.\", \"retriever\": retriever_sentences, \"prompt\": prompt_sentences},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up MultiRetrievalQAChain where we take two of our retrivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_retrieval_qa_chain = MultiRetrievalQAChain.from_retrievers(\n",
    "    llm=chat,\n",
    "    retriever_infos=retriever_infos,\n",
    "    default_retriever=retriever_articles,\n",
    "    default_prompt=prompt_articles\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The article with the highest citation count is \"Lapointe, Liette; Rivard, Suzanne. 2005. A Multilevel Model of Resistance to Information Technology Implementation\" with 296 citations.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which article name has the highest citation count.\"\n",
    "response = multi_retrieval_qa_chain.invoke({\"input\": query})\n",
    "\n",
    "print(\"Answer:\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: According to the provided context, the article with a citation count of 296 (not 299) is:\n",
      "\n",
      "7061 Lapointe, Liette; Rivard, Suzanne 2005 A Multilevel Model of Resistance to Information Technology Implementation Management Information Systems Quarterly\n"
     ]
    }
   ],
   "source": [
    "query = \"Which article has a citation count of 299\"\n",
    "response = multi_retrieval_qa_chain.invoke({\"input\": query})\n",
    "\n",
    "print(\"Answer:\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: According to the provided context, one article was published in the year 2005.\n"
     ]
    }
   ],
   "source": [
    "query = \"How many articles were published in 2005.\"\n",
    "response = multi_retrieval_qa_chain.invoke({\"input\": query})\n",
    "\n",
    "print(\"Answer:\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: According to the provided context, the article with a citation count of 0 is:\n",
      "\n",
      "1658 Burton-Jones, Andrew; Gallivan, Michael J. 2007 Toward a Deeper Understanding of System Usage in Organizations: A Multilevel Perspective Management Information Systems Quarterly\n"
     ]
    }
   ],
   "source": [
    "query = \"Which articles have citation count of 0, can be more of them\"\n",
    "response = multi_retrieval_qa_chain.invoke({\"input\": query})\n",
    "\n",
    "print(\"Answer:\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the answears are wrong so lets try to take adifferent approach with Ensemble Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[retriever_articles, retriever_sentences],\n",
    "    weights=[0.5, 0.5]  # Adjust the weights as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question accurately.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Provide a concise and relevant answer below:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=custom_prompt_template, input_variables=['context', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_retrieval_qa_chain = MultiRetrievalQAChain.from_retrievers(\n",
    "    llm=chat,\n",
    "    retriever_infos=[{\"name\": \"Ensemble\", \"description\": \"Combines results from article and sentence retrievers.\", \"retriever\": ensemble_retriever, \"prompt\": prompt}],\n",
    "    default_retriever=ensemble_retriever,\n",
    "    default_prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided contexts, the title with the highest citation count is \"A Multilevel Model of Resistance to Information Technology Implementation\" with 296 citations.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which title name has the highest citation count.\"\n",
    "response = multi_retrieval_qa_chain.invoke({\"input\": query})\n",
    "\n",
    "print(\"Answer:\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: According to the provided context, the article \"A Multilevel Model of Resistance to Information Technology Implementation\" by Lapointe and Rivard (2005) has the most citations, with 296 citations.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which article has 299 citation.\"\n",
    "response = multi_retrieval_qa_chain.invoke({\"input\": query})\n",
    "\n",
    "print(\"Answer:\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The article \"Understanding User Responses to Information Technology: A Coping Model of User Adaptation\" has 299 citations.\n"
     ]
    }
   ],
   "source": [
    "query = \"how many ciatation does article named Understanding User Responses to Information Technology: A Coping Model of User Adaptation has.\"\n",
    "response = multi_retrieval_qa_chain.invoke({\"input\": query})\n",
    "\n",
    "print(\"Answer:\", response[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
